{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import random\n",
    "from pprint import pprint\n",
    "from graphviz import Digraph\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_data_preprocessing():\n",
    "    df_train_data = pd.read_csv(\"sample_train.csv\")\n",
    "    review_column=np.array(list(df_train_data[\"reviews.text\"]))\n",
    "\n",
    "    df_train_data[\"counts_No\"]=np.char.count(review_column, sub ='No') \n",
    "    df_train_data[\"counts_Please\"]=np.char.count(review_column, sub ='Please') \n",
    "    df_train_data[\"counts_Thank\"]=np.char.count(review_column, sub ='Thank') \n",
    "    df_train_data[\"counts_apologize\"]=np.char.count(review_column, sub ='apologize') \n",
    "    df_train_data[\"counts_bad\"]=np.char.count(review_column, sub ='bad') \n",
    "    df_train_data[\"counts_clean\"]=np.char.count(review_column, sub ='clean') \n",
    "    df_train_data[\"counts_comfortable\"]=np.char.count(review_column, sub ='comfortable') \n",
    "    df_train_data[\"counts_dirty\"]=np.char.count(review_column, sub ='dirty') \n",
    "    df_train_data[\"counts_enjoyed\"]=np.char.count(review_column, sub ='enjoyed') \n",
    "    df_train_data[\"counts_friendly\"]=np.char.count(review_column, sub ='friendly') \n",
    "    df_train_data[\"counts_glad\"]=np.char.count(review_column, sub ='glad') \n",
    "    df_train_data[\"counts_good\"]=np.char.count(review_column, sub ='good') \n",
    "    df_train_data[\"counts_great\"]=np.char.count(review_column, sub ='great') \n",
    "    df_train_data[\"counts_happy\"]=np.char.count(review_column, sub ='happy') \n",
    "    df_train_data[\"counts_hot\"]=np.char.count(review_column, sub ='hot') \n",
    "    df_train_data[\"counts_issues\"]=np.char.count(review_column, sub ='issues') \n",
    "    df_train_data[\"counts_nice\"]=np.char.count(review_column, sub ='nice') \n",
    "    df_train_data[\"counts_noise\"]=np.char.count(review_column, sub ='noise') \n",
    "    df_train_data[\"counts_old\"]=np.char.count(review_column, sub ='old') \n",
    "    df_train_data[\"counts_poor\"]=np.char.count(review_column, sub ='poor') \n",
    "    df_train_data[\"counts_right\"]=np.char.count(review_column, sub ='right') \n",
    "    df_train_data[\"counts_small\"]=np.char.count(review_column, sub ='small') \n",
    "    df_train_data[\"counts_smell\"]=np.char.count(review_column, sub ='smell') \n",
    "    df_train_data[\"counts_sorry\"]=np.char.count(review_column, sub ='sorry') \n",
    "    df_train_data[\"counts_wonderful\"]=np.char.count(review_column, sub ='wonderful') \n",
    "    \n",
    "    \n",
    "\n",
    "    cols=[]\n",
    "    for i in range(25):\n",
    "        cols.append(i)\n",
    "\n",
    "    df_train_data=df_train_data.drop(df_train_data.columns[cols], axis =1)\n",
    "\n",
    "    df_train_data = df_train_data.rename(columns={\"rating\": \"label\"})\n",
    "\n",
    "\n",
    "    df_train_data.pop(\"reviews.text\")\n",
    "    df2=df_train_data.pop(\"label\")\n",
    "    df_train_data[\"label\"]=df2\n",
    "#     df_train_data[\"label_encoded\"]= (df_train_data[\"label\"].replace({\"Negative\":0,\"Positive\":1}))\n",
    "            \n",
    "    \n",
    "    return df_train_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_data_preprocessing():\n",
    "    \n",
    "    df_test_data = pd.read_csv(\"sample_dev.csv\")\n",
    "    \n",
    "    review_column_test=np.array(list(df_test_data[\"reviews.text\"]))\n",
    "\n",
    "    df_test_data[\"counts_No\"]=np.char.count(review_column_test, sub ='No') \n",
    "    df_test_data[\"counts_Please\"]=np.char.count(review_column_test, sub ='Please') \n",
    "    df_test_data[\"counts_Thank\"]=np.char.count(review_column_test, sub ='Thank') \n",
    "    df_test_data[\"counts_apologize\"]=np.char.count(review_column_test, sub ='apologize') \n",
    "    df_test_data[\"counts_bad\"]=np.char.count(review_column_test, sub ='bad') \n",
    "    df_test_data[\"counts_clean\"]=np.char.count(review_column_test, sub ='clean') \n",
    "    df_test_data[\"counts_comfortable\"]=np.char.count(review_column_test, sub ='comfortable') \n",
    "    df_test_data[\"counts_dirty\"]=np.char.count(review_column_test, sub ='dirty') \n",
    "    df_test_data[\"counts_enjoyed\"]=np.char.count(review_column_test, sub ='enjoyed') \n",
    "    df_test_data[\"counts_friendly\"]=np.char.count(review_column_test, sub ='friendly') \n",
    "    df_test_data[\"counts_glad\"]=np.char.count(review_column_test, sub ='glad') \n",
    "    df_test_data[\"counts_good\"]=np.char.count(review_column_test, sub ='good') \n",
    "    df_test_data[\"counts_great\"]=np.char.count(review_column_test, sub ='great') \n",
    "    df_test_data[\"counts_happy\"]=np.char.count(review_column_test, sub ='happy') \n",
    "    df_test_data[\"counts_hot\"]=np.char.count(review_column_test, sub ='hot') \n",
    "    df_test_data[\"counts_issues\"]=np.char.count(review_column_test, sub ='issues') \n",
    "    df_test_data[\"counts_nice\"]=np.char.count(review_column_test, sub ='nice') \n",
    "    df_test_data[\"counts_noise\"]=np.char.count(review_column_test, sub ='noise') \n",
    "    df_test_data[\"counts_old\"]=np.char.count(review_column_test, sub ='old') \n",
    "    df_test_data[\"counts_poor\"]=np.char.count(review_column_test, sub ='poor') \n",
    "    df_test_data[\"counts_right\"]=np.char.count(review_column_test, sub ='right') \n",
    "    df_test_data[\"counts_small\"]=np.char.count(review_column_test, sub ='small') \n",
    "    df_test_data[\"counts_smell\"]=np.char.count(review_column_test, sub ='smell') \n",
    "    df_test_data[\"counts_sorry\"]=np.char.count(review_column_test, sub ='sorry') \n",
    "    df_test_data[\"counts_wonderful\"]=np.char.count(review_column_test, sub ='wonderful') \n",
    "\n",
    "\n",
    "    cols=[]\n",
    "    for i in range(25):\n",
    "        cols.append(i)\n",
    "\n",
    "    df_test_data=df_test_data.drop(df_test_data.columns[cols], axis =1)\n",
    "\n",
    "    df_test_data = df_test_data.rename(columns={\"rating\": \"label\"})\n",
    "\n",
    "    df_test_data.pop(\"reviews.text\")\n",
    "    df2=df_test_data.pop(\"label\")\n",
    "    df_test_data[\"label\"]=df2\n",
    "#     df_test_data[\"label_encoded\"]= (df_test_data[\"label\"].replace({\"Negative\":0,\"Positive\":1}))\n",
    "    \n",
    "    return df_test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_preprocessing():\n",
    "    df_test_data = pd.read_csv(\"sample_test.csv\")\n",
    "\n",
    "    review_column_test=np.array(list(df_test_data[\"reviews.text\"]))\n",
    "\n",
    "    df_test_data[\"counts_No\"]=np.char.count(review_column_test, sub ='No') \n",
    "    df_test_data[\"counts_Please\"]=np.char.count(review_column_test, sub ='Please') \n",
    "    df_test_data[\"counts_Thank\"]=np.char.count(review_column_test, sub ='Thank') \n",
    "    df_test_data[\"counts_apologize\"]=np.char.count(review_column_test, sub ='apologize') \n",
    "    df_test_data[\"counts_bad\"]=np.char.count(review_column_test, sub ='bad') \n",
    "    df_test_data[\"counts_clean\"]=np.char.count(review_column_test, sub ='clean') \n",
    "    df_test_data[\"counts_comfortable\"]=np.char.count(review_column_test, sub ='comfortable') \n",
    "    df_test_data[\"counts_dirty\"]=np.char.count(review_column_test, sub ='dirty') \n",
    "    df_test_data[\"counts_enjoyed\"]=np.char.count(review_column_test, sub ='enjoyed') \n",
    "    df_test_data[\"counts_friendly\"]=np.char.count(review_column_test, sub ='friendly') \n",
    "    df_test_data[\"counts_glad\"]=np.char.count(review_column_test, sub ='glad') \n",
    "    df_test_data[\"counts_good\"]=np.char.count(review_column_test, sub ='good') \n",
    "    df_test_data[\"counts_great\"]=np.char.count(review_column_test, sub ='great') \n",
    "    df_test_data[\"counts_happy\"]=np.char.count(review_column_test, sub ='happy') \n",
    "    df_test_data[\"counts_hot\"]=np.char.count(review_column_test, sub ='hot') \n",
    "    df_test_data[\"counts_issues\"]=np.char.count(review_column_test, sub ='issues') \n",
    "    df_test_data[\"counts_nice\"]=np.char.count(review_column_test, sub ='nice') \n",
    "    df_test_data[\"counts_noise\"]=np.char.count(review_column_test, sub ='noise') \n",
    "    df_test_data[\"counts_old\"]=np.char.count(review_column_test, sub ='old') \n",
    "    df_test_data[\"counts_poor\"]=np.char.count(review_column_test, sub ='poor') \n",
    "    df_test_data[\"counts_right\"]=np.char.count(review_column_test, sub ='right') \n",
    "    df_test_data[\"counts_small\"]=np.char.count(review_column_test, sub ='small') \n",
    "    df_test_data[\"counts_smell\"]=np.char.count(review_column_test, sub ='smell') \n",
    "    df_test_data[\"counts_sorry\"]=np.char.count(review_column_test, sub ='sorry') \n",
    "    df_test_data[\"counts_wonderful\"]=np.char.count(review_column_test, sub ='wonderful') \n",
    "\n",
    "\n",
    "    cols=[]\n",
    "    for i in range(25):\n",
    "        cols.append(i)\n",
    "\n",
    "    df_test_data=df_test_data.drop(df_test_data.columns[cols], axis =1)\n",
    "    df_test_data.pop(\"reviews.text\")\n",
    "\n",
    "    \n",
    "    return df_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    \n",
    "    label_column = data\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node: # el dayra elly bnersmha fe decision tree\n",
    "\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature = feature #best feature to split the node on \n",
    "        self.threshold = threshold  #value of question in node \n",
    "        self.left = left#lleft sub-tree\n",
    "        self.right = right#right sub-tree\n",
    "        self.value = value#the majority class prediction if this is leaf it will have value otherwise it will be none\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, n_feats=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feats = n_feats\n",
    "        self.root = None #our root node in order to start traversal from it\n",
    "        \n",
    "    def check_purity(self,data):\n",
    "        \n",
    "        label_column = data\n",
    "        unique_classes = np.unique(label_column)\n",
    "\n",
    "        if len(unique_classes) == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "    def fit(self, X, y): #X training data y training labels\n",
    "        #X.shape[0] returns no of rows X.shape[1] returns no of columns \n",
    "        #X.shape[1] ==> no of columns in training data == no of features\n",
    "        #so in in fit we know no of features in training data and store it in our class decision tree\n",
    "        #we also set our root as the return of function grow_tree\n",
    "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):#output test labels\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):#depth is just zero at begining \n",
    "        n_samples, n_features = X.shape #notice n_features =25 in our case exclude last 2 columns  \n",
    "        n_labels = len(np.unique(y))#in our case +ve and -ve  n_label=2\n",
    "        # stopping criteria\n",
    "        if (depth >= self.max_depth # if depth icreases than specified stop growing the tree and make  it leaf node\n",
    "                or n_labels == 1 # if we have only one class so no need to grow more \n",
    "                or n_samples < self.min_samples_split#if we have small samples so take majority class predicition\n",
    "                or self.check_purity(y)==True \n",
    "                or depth==7):\n",
    "            leaf_value = self.classify_data(y)# calculating majority class predicition\n",
    "            return Node(value=leaf_value)\n",
    "        #here he makes gready search thats why he usues random function but actually feat_idxs contains all feature \n",
    "        #indices stored in it but randomly for example if we have 4 features\n",
    "        #self.n_feats =4 so we can loop from 0-->3\n",
    "        #feat_idxs=[1,3,2,0] for example is this to make randomness and greedy thinking\n",
    "\n",
    "        feat_idxs = np.random.choice(n_features, self.n_feats, replace=False)\n",
    "\n",
    "        # greedily select the best split according to information gain\n",
    "        best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)\n",
    "        \n",
    "        # grow the children that result from the split\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth+1)    \n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth+1)\n",
    "        if left.is_leaf_node() and right.is_leaf_node() and right.value==left.value:\n",
    "            v=right.value\n",
    "            right=None\n",
    "            left=None\n",
    "            return Node(value=v)\n",
    "            \n",
    "        else :\n",
    "            return Node(best_feat, best_thresh, left, right)\n",
    "            \n",
    "            \n",
    "\n",
    "    def _best_criteria(self, X, y, feat_idxs):\n",
    "        best_gain = -1\n",
    "        split_idx, split_thresh = None, None\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx] #feature column \n",
    "            thresholds = np.unique(X_column)#potential splits= unique values in the features column\n",
    "            for threshold in thresholds:#loop over each threashold and calculate the information gain of each \n",
    "                #and the one with the most information gain will be the best threshold for this feature column\n",
    "                gain = self._information_gain(y, X_column, threshold)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_thresh = threshold\n",
    "\n",
    "        return split_idx, split_thresh\n",
    "\n",
    "    def _information_gain(self, y, X_column, split_thresh):\n",
    "        # parent loss\n",
    "        parent_entropy = entropy(y)\n",
    "\n",
    "        # generate split\n",
    "        left_idxs, right_idxs = self._split(X_column, split_thresh)\n",
    "\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        # compute the weighted avg. of the loss for the children\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = entropy(y[left_idxs]), entropy(y[right_idxs])\n",
    "        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r\n",
    "\n",
    "        # information gain is difference in loss before vs. after split\n",
    "        ig = parent_entropy - child_entropy\n",
    "        return ig\n",
    "\n",
    "    def _split(self, X_column, split_thresh):\n",
    "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        if node.threshold !=None:\n",
    "            if x[node.feature] <= node.threshold:\n",
    "                return self._traverse_tree(x, node.left)\n",
    "            return self._traverse_tree(x, node.right)\n",
    "\n",
    "    \n",
    "    def classify_data(self,data):\n",
    "    \n",
    "        label_column = data\n",
    "        unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "        if len(counts_unique_classes):\n",
    "            index = counts_unique_classes.argmax()\n",
    "            classification = unique_classes[index]\n",
    "\n",
    "            return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tree(COLUMN_HEADERS,tree_node,graph,parent,counter=0):\n",
    "    \n",
    "#     print(tree_node.value)\n",
    "    \n",
    "    # base case\n",
    "    if tree_node.is_leaf_node():\n",
    "       #adding this line to get different ids\n",
    "        \n",
    "        if tree_node.value==\"Positive\":\n",
    "            id=\"positive_\"+str(counter)\n",
    "            node=pydot.Node(id, label=tree_node.value,style=\"filled\", fillcolor=\"#FF7597\")\n",
    "        else:\n",
    "            \n",
    "            id=\"negative_\"+str(counter)\n",
    "            node=pydot.Node(id, label=tree_node.value,style=\"filled\", fillcolor=\"#988185\")\n",
    "#         print(\"id :\",id)\n",
    "        graph.add_node(node)\n",
    "        edge = pydot.Edge(parent,id)\n",
    "        edge.set_color(\"#342B2D\")\n",
    "        graph.add_edge(edge)\n",
    "        \n",
    "\n",
    "        return\n",
    "\n",
    "    else:\n",
    "\n",
    "        #instead of += ==> =\n",
    "        counter+=random.randint(0,1000)\n",
    "        \n",
    "        question = \"{} <= {}\".format(COLUMN_HEADERS[tree_node.feature], tree_node.threshold)\n",
    "        id=\"question_\"+str(counter)\n",
    "        \n",
    "        \n",
    "        if parent==None:\n",
    "            id=question\n",
    "\n",
    "        plot_tree(COLUMN_HEADERS,tree_node.left,graph,id,counter)\n",
    "\n",
    "        plot_tree(COLUMN_HEADERS,tree_node.right,graph,id,counter)\n",
    "#         print(\"parent : \",parent)\n",
    "#         print(\"child  : \",question)\n",
    "        \n",
    "        if parent !=None:\n",
    "            graph.add_node(pydot.Node(id, label=question))\n",
    "            edge = pydot.Edge(parent,id)\n",
    "            edge.set_color(\"#342B2D\")\n",
    "            graph.add_edge(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tree(COLUMN_HEADERS,tree_node):\n",
    "    if tree_node.is_leaf_node():\n",
    "        print(tree_node.value)\n",
    "        return\n",
    "    else:\n",
    "        question = \"{} <= {}\".format(COLUMN_HEADERS[tree_node.feature], tree_node.threshold)   \n",
    "        print(question)\n",
    "        show_tree(COLUMN_HEADERS,tree_node.left)\n",
    "        show_tree(COLUMN_HEADERS,tree_node.right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review=input(\"please enter the sample review :    \")\n",
    "\n",
    "def review_counts_extractor(review):\n",
    "    \n",
    "    review_column_test=np.array(review)\n",
    "\n",
    "    data_list=[]\n",
    "    data_list.append(np.char.count(review_column_test, sub ='No'))\n",
    "    data_list.append(np.char.count(review_column_test, sub ='Please'))\n",
    "    data_list.append(np.char.count(review_column_test, sub ='Thank'))\n",
    "    data_list.append(np.char.count(review_column_test, sub ='apologize'))\n",
    "    data_list.append(np.char.count(review_column_test, sub ='bad')) \n",
    "    data_list.append(np.char.count(review_column_test, sub ='clean'))\n",
    "    data_list.append(np.char.count(review_column_test, sub ='comfortable')) \n",
    "    data_list.append(np.char.count(review_column_test, sub ='dirty'))\n",
    "    data_list.append(np.char.count(review_column_test,sub='enjoyed')) \n",
    "    data_list.append(np.char.count(review_column_test,sub='friendly')) \n",
    "    data_list.append(np.char.count(review_column_test, sub ='glad')) \n",
    "    data_list.append(np.char.count(review_column_test, sub ='good')) \n",
    "    data_list.append(np.char.count(review_column_test, sub ='great')) \n",
    "    data_list.append(np.char.count(review_column_test, sub ='happy')) \n",
    "    data_list.append(np.char.count(review_column_test, sub ='hot'))\n",
    "    data_list.append(np.char.count(review_column_test, sub ='issues')) \n",
    "    data_list.append(np.char.count(review_column_test, sub ='nice'))\n",
    "    data_list.append(np.char.count(review_column_test, sub ='noise'))\n",
    "    data_list.append(np.char.count(review_column_test, sub ='old')) \n",
    "    data_list.append(np.char.count(review_column_test, sub ='poor'))\n",
    "    data_list.append(np.char.count(review_column_test, sub ='right')) \n",
    "    data_list.append(np.char.count(review_column_test, sub ='small')) \n",
    "    data_list.append(np.char.count(review_column_test, sub ='smell')) \n",
    "    data_list.append(np.char.count(review_column_test, sub ='sorry')) \n",
    "    data_list.append(np.char.count(review_column_test, sub ='wonderful'))\n",
    "    data=np.array(data_list)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from PyQt5.QtWidgets import QApplication, QDialog,QFrame\n",
    "from PyQt5.QtCore import QCoreApplication,Qt\n",
    "from PyQt5.QtGui import QPixmap\n",
    "import Mainf\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "class DtreeGui(QtWidgets.QMainWindow):\n",
    "    def __init__(self,parent = None):\n",
    "        QtWidgets.QMainWindow.__init__(self,parent)\n",
    "        self.ui = Mainf.Ui_MainWindow()\n",
    "        self.ui.setupUi(self)\n",
    "        \n",
    "        #adding buttons functions\n",
    "        self.ui.trainBtn.clicked.connect(self.startModelTraining)\n",
    "        self.ui.accuracyBtn.clicked.connect(self.calculateAccuracy)\n",
    "        self.ui.enterBtn.clicked.connect(self.predictUserInput)\n",
    "        self.ui.predictBtn.clicked.connect(self.viewFile)\n",
    "        \n",
    "        #change table size policy\n",
    "        self.ui.accuracyTable.setSizeAdjustPolicy(QtWidgets.QAbstractScrollArea.AdjustToContents)\n",
    "        self.ui.predictFile.setSizeAdjustPolicy(QtWidgets.QAbstractScrollArea.AdjustToContents)\n",
    "        \n",
    "        #remove outlines\n",
    "        self.ui.Input.setFrameStyle(QFrame.NoFrame)\n",
    "        self.ui.accuracyTable.setFrameStyle(QFrame.NoFrame)\n",
    "        self.ui.predictFile.setFrameStyle(QFrame.NoFrame)\n",
    "        \n",
    "        self.td = training_data_preprocessing()\n",
    "        self.clf = DecisionTree(max_depth=5)\n",
    "        self.clf.fit(self.td.values[:,0:25],self.td.values[:,-1])\n",
    "        \n",
    "    #adding button functionality\n",
    "    def startModelTraining(self):\n",
    "        \n",
    "        start_time = int(round(time.time()*1000))\n",
    "        self.ui.indicator.setText(\"Started\")\n",
    "        rowN,colN = self.td.shape                   \n",
    "        COLUMN_HEADERS = self.td.columns \n",
    "        graph = pydot.Dot(graph_type='graph')\n",
    "        plot_tree(COLUMN_HEADERS,self.clf.root,graph,parent=None,counter=0)\n",
    "        graph.write_png('Tree_plot.png')\n",
    "        \n",
    "        \n",
    "        img = cv2.imread('Tree_plot.png', cv2.IMREAD_UNCHANGED)\n",
    "        scale_percent = 60 # percent of original size\n",
    "        width = int(img.shape[1] * scale_percent / 100)\n",
    "        height = int(img.shape[0])\n",
    "        dim = (width, height)\n",
    "        resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        cv2.imwrite('Tree_plot.png',resized)\n",
    "        \n",
    "        \n",
    "        \n",
    "        pixmap = QPixmap('Tree_plot.png')\n",
    "        end_time = int(round(time.time()*1000))\n",
    "        self.ui.indicator.setText(\"finished\")\n",
    "        self.ui.execTime.setText(str(end_time-start_time)+\" Milli Seconds\")\n",
    "        self.ui.treeImg.setPixmap(pixmap)\n",
    "\n",
    "        \n",
    "    def calculateAccuracy(self):\n",
    "        evd =  evaluation_data_preprocessing()\n",
    "        evaluation_data =evd.values\n",
    "        rowN,colN = evaluation_data.shape\n",
    "        self.ui.accuracyTable.setColumnCount(colN)\n",
    "        self.ui.accuracyTable.setRowCount(rowN)\n",
    "        self.ui.accuracyTable.setHorizontalHeaderLabels(list(evd.columns))\n",
    "        for i in range(rowN):\n",
    "            for j in range(colN):\n",
    "                item = QtWidgets.QTableWidgetItem(str((evaluation_data)[i][j]))\n",
    "                item.setTextAlignment(Qt.AlignHCenter)\n",
    "                self.ui.accuracyTable.setItem(i,j,item)\n",
    "        self.ui.accuracyTable.resizeColumnsToContents()\n",
    "        X_test=evaluation_data[:,0:25]\n",
    "        y_test=evaluation_data[:,-1]\n",
    "        y_pred = self.clf.predict(X_test)\n",
    "        acc = accuracy(y_test, y_pred)\n",
    "        self.ui.accuracy.setText(str(acc))\n",
    "        \n",
    "       \n",
    "    def predictUserInput(self):\n",
    "        review = self.ui.Input.toPlainText()\n",
    "        data=review_counts_extractor(review)\n",
    "        # print(data)\n",
    "        feature_cols = ['counts_No', 'counts_Please', 'counts_Thank', 'counts_apologize', 'counts_bad', 'counts_clean', 'counts_comfortable', 'counts_dirty','counts_enjoyed','counts_friendly','counts_glad','counts_good','counts_great','counts_happy','counts_hot','counts_issues','counts_nice','counts_noise','counts_old','counts_poor','counts_right','counts_small','counts_smell','counts_sorry','counts_wonderful']\n",
    "        ser = pd.Series(data,index=feature_cols)\n",
    "        self.ui.prediction.setText(str(self.clf._traverse_tree(ser, self.clf.root)))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def viewFile(self):\n",
    "        df_testing=test_data_preprocessing()\n",
    "        arr_test=df_testing.values\n",
    "        prediction_arr=self.clf.predict(arr_test[:,0:25])\n",
    "        df_testing[\"prediction\"]=prediction_arr.tolist()\n",
    "        # df_evaluate\n",
    "        file= pd.DataFrame(data=df_testing[\"prediction\"], columns=['prediction'])\n",
    "        file.to_csv('test_prediction_file.csv')\n",
    "        rowN,colN = df_testing.values.shape\n",
    "        self.ui.predictFile.setColumnCount(colN)\n",
    "        self.ui.predictFile.setRowCount(rowN)\n",
    "        self.ui.predictFile.setHorizontalHeaderLabels(list(df_testing.columns))\n",
    "        for i in range(rowN):\n",
    "            for j in range(colN):\n",
    "                item = QtWidgets.QTableWidgetItem(str((df_testing.values)[i][j]))\n",
    "                item.setTextAlignment(Qt.AlignHCenter)\n",
    "                self.ui.predictFile.setItem(i,j,item)\n",
    "       # self.ui.predictFile.resizeColumnsToContents()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    app = QCoreApplication.instance()\n",
    "    if app is None:\n",
    "        app = QApplication(sys.argv)\n",
    "     \n",
    "    #adding css file\n",
    "    styleSheet=\"style.css\"\n",
    "    with open(styleSheet,\"r\") as f:\n",
    "        app.setStyleSheet(f.read())\n",
    "        \n",
    "    gui = DtreeGui()\n",
    "    gui.show()\n",
    "    app.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
